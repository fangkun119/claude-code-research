我看见的世界 8：神经网络算法迎来了人工智能的寒武纪大爆发

各位书友大家好，欢迎继续做客老齐的读书圈，今天我们继续来讲这本书，我看见的世界。

昨天说到了，在第三届 ImageNet 大赛上，李飞飞终于等到了他要的卷积神经网络算法，杰弗里·辛顿的团队脱颖而出，一时之间，研究视觉识别的科学家，齐聚佛罗伦萨的主会场，感知这个 AlexNet 所带来的震撼。

他们主要是想了解一下这个识别的过程。跟所有神经网络一样，AlexNet 一开始都是无形的、懒惰的，就像虚空中的一块挂毯。然后学习的过程开始了，面对图集当中随机选择的图片，神经网络的任务，是从上千个标签当中，选择一个正确的标签，对图片进行标注。这个过程周而复始，不断重复，一开始错误连连。比如它会把一个蘑菇误认为是瓶盖，把一个拖车说成是电吉他。这就是典型的胡说八道阶段。

但这些失败并非是无用功。错误会触发纠正信号，在网络的数千万个组成的部分中，逐渐蔓延开来，同时对每个部分对于结果的贡献进行评估，并按照比例推动它们下一次采取的行动。简单来说，就是中国那句古话：失败是成功之母，成功是成功之父。它就是不断地试错，这样就慢慢知道哪些是错，哪些是对了。就跟小孩学东西一样，家长会诱导：“你告诉我哪个是苹果？这个，不对，这是梨。这个？也不对，这叫香蕉。这个？对了，这是苹果。那你再告诉我，哪个是香蕉？不对，这是橘子。”整个过程看似幼稚，但却一点一点地增加它的识别正确率。这个游戏玩几天之后，小孩就能准确地识别苹果、梨、香蕉、橘子这些日常的水果了。

人工智能也一样。一开始效果并不显著，之前犯过的错误，之后也还会再出错，只是错误的概率会越来越低。如此循环往复，直到正确为止。随着它一轮一轮的识别，你会惊奇地发现，它的正确率越来越高，而且还越来越完备，给出的识别信息也越来越具体。不但能识别出汽车，还能识别出敞篷车。

李飞飞也被这一切震撼到了。他知道自己找对路了。生物视觉的出现，导致远古海洋波涛下的寒武纪大爆发，距今已经有 5 亿年的时间。而如今，他们很难不去联想，我们是不是正处于一个类似拐点的边缘。机器视觉的兴起，是否会引发一轮数字进化的新浪潮。

突然之间，人工智能的寒冬开始消退，神经网络等灵活的算法，开始重新焕发升级，真正的大规模数据集横空出世。AlexNet 已经展示了算法和数据集在实践中的强大威力，一时之间，科学界的热情又起来了。然后出现了一个新的说法，叫做机器学习。

此时，他们也从默默无闻，逐渐走上前台。一时之间，各种采访的需求纷至沓来。在生活上，塞巴斯蒂安·特龙教授离开了斯坦福大学，去了谷歌负责自动驾驶项目的研发，于是空出了一个岗位。他的老公西尔维奥此时也已经是 3D 感知算法领域的领军人物，所以填补了这个空白，来到了斯坦福大学任职。这样他们夫妻二人终于不用再两地分居。

另一个离开斯坦福大学的是吴恩达。他卸任了人工智能实验室主任的职务，先去了谷歌，后入职百度。而李飞飞则成为了他的继任者，挑起了斯坦福大学人工智能实验室的重担。这一下让他成为了全美最前沿的人工智能科学家，也成了学术界的明星。

他们也知道，人工智能的视觉识别才刚刚开始，还远没有成熟。拿 ImageNet 来说，它虽然规模庞大、细节丰富，但它并非完美。虽有分类特别精细，但有时候一些明显存在差异的概念，依然会被归为同一类别，概念范围相对粗糙。同类概念之间的差异也较为明显。这主要是方便他们当时完成任务，但如果进一步精细，还有的是工作可做。比如拿汽车举例，能识别出汽车只是第一步，能不能识别出这是一辆丰田汽车，需要有更详细的标签，然后还得能识别出这是丰田雅力士汽车，再然后还得能认出，他到底是 2008 款还是 2009 款，甚至是基础款还是运动款，高配版还是低配版。所以分类还无穷无尽。

再比如鸟，机器识别出这是一只鸟并不难，但问题是这是什么鸟，难度就大了。他们在 ImageNet 里也只收录了 59 种鸟类，而实际上，全世界有 1 万种鸟类，完全不在一个数量级。所以用一个互联网的词汇来说，这就是颗粒度的问题。越往下做，颗粒度就越是细致，但也意味着工作量将翻倍的提升。他们现在的所谓成就，也只是皮毛，只能证明道路的方向是正确的，仅此而已。

在想清楚这些东西之后，他的学生们满脸写满了绝望的表情，不知道这涵盖万事万物的数据库到底该如何进行下去。一开始他们也没有想好后面的答案。

AlexNet 催生了新一代的神经网络，每年都取得令人惊叹的飞跃，这几乎颠覆了之前的技术路径，让之前的向量机和贝叶斯网络算法基本都被淘汰了。现在所有的论文、讲座，几乎都在谈论神经网络算法的新发展。也有越来越多的神经网络模型参加 ImageNet 挑战赛。如今这已经变成了计算机视觉领域的基础赛事，这也完成了他们的心愿。而更重要的是，每年机器的表现都会有进步，误差率正在变得越来越小，也越来越接近于人类的识别水平。要知道，机器的算法和人脑是有区别的。人脑更擅长识别和逻辑思维，而计算机则在知识储备和算力方面远超人脑。如果说在识别上，计算机能够跟人脑接近，那么也就意味着在人工智能方面，它可能早已经让人类大脑望尘莫及。这个观点，库兹韦尔也提到过。我们在《奇点临近》那本书里讲过，库兹韦尔认为，一旦机器通过了图灵测试，意味着它的智商其实已经远超人类。因为机器要让人类无法识别，那就必然会故意控分和卖破绽。这用现在的流行语来说，就叫做轻松拿捏。那么一个轻松拿捏人类智商的东西，必然是已经大幅领先的。他甚至知道，在什么地方，应该犯个什么样的错误。这就太可怕了。

李飞飞其实这时候也知道，他们研究的不再是神经网络，而是开始向整个人工智能拓展。他们把越来越多的数据导入了算法当中，甚至包括了人口普查、街景地图等等。甚至他还从生活中找到很多灵感。人类所能识别的，绝不仅仅是事物这么简单。拿他们家来说，他老公做饭的时候，他母亲就会努力地在尽可能的收拾干净。他只需要看母亲一眼，就大概知道他的情绪和状态。有时候家庭和睦，也有时候气氛紧张，还有时候，看他的表情，就知道身体并不舒服。他也在想，自己到底是通过什么信息，得到的这些推断。又该如何让机器去计算这种感知。越是想这些，他就越觉得，还有许多的工作需要做。人工智能就好像一个单线程的天才，他会帮你完成一些工作，满足降低错误率的这些指标，但是他却无法像人类一样，感受到全局的变化。举个例子，比如外面着火了，人类肯定会放下手里的事情，率先跑出去救火，而人工智能可能还是会按部就班地执行之前的指令。

对于该如何海量的训练他们的模型，他们也想了很多的办法。比如他有一个博士生，叫做安德烈，提出了一个新的大胆的想法，就是把卷积神经网络和递归神经网络进行配对，一个负责对视觉信息进行编码，同时将它跟单词配对，另一个则负责生成语言。然后以成对出现的图像和人类文字描述为基础，训练他的模型。这让李飞飞眼前一亮，觉得这个事似乎很有意义。

此时他们的谷歌街景汽车项目已经完成，收集了极为惊人的数据量：200 个城市、5000 多万张图片，算法已经识别了 2200 多万辆汽车，几乎占全美汽车总量的 10%。甚至他们在这些看似无关的数据当中，得到了一些很有意思的发现。那么这又是什么呢？机器学习又将有怎样的发展呢？